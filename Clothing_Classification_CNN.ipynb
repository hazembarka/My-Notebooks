{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Clothing_Classification_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAqvSV-zFm19",
        "colab_type": "text"
      },
      "source": [
        "# Clothing Apparel Classification :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfhup2u06lil",
        "colab_type": "text"
      },
      "source": [
        "## 1- Importing & exploring the dataset :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbjOWtxJFm2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import necessary Libraries\n",
        "#!pip install tensorflow==1.14\n",
        "import numpy as np\n",
        "from keras.datasets import fashion_mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tlPlQtdG1Ev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load fashion MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbs2QA6qFm26",
        "colab_type": "code",
        "outputId": "8b8cee5b-e6ad-4d9d-fc93-891d34e65182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Explore the dataset\n",
        "# Check the shape and size of x_train, x_test, y_train, y_test\n",
        "print (\"Number of samples/observations in training data: \" + str(len(x_train)))\n",
        "print (\"Number of labels in training data: \" + str(len(y_train)))\n",
        "print (\"Dimensions of a single image in x_train:\" + str(x_train[0].shape))\n",
        "print(\"-------------------------------------------------------------\")\n",
        "print (\"Number of samples/observations in test data: \" + str(len(x_test)))\n",
        "print (\"Number of labels in test data: \" + str(len(y_test)))\n",
        "print (\"Dimensions of single image in x_test:\" + str(x_test[0].shape))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples/observations in training data: 60000\n",
            "Number of labels in training data: 60000\n",
            "Dimensions of a single image in x_train:(28, 28)\n",
            "-------------------------------------------------------------\n",
            "Number of samples/observations in test data: 10000\n",
            "Number of labels in test data: 10000\n",
            "Dimensions of single image in x_test:(28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7IrFmtbFm3Q",
        "colab_type": "code",
        "outputId": "d948e8da-6301-4f22-91ec-d562ef1810e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.subplot(231)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(232)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(233)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(234)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(235)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "\n",
        "# Visualize the images\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD6CAYAAAC4RRw1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhRAiUzSACyFEpmgAF0KITNEALoQQmfL/ePT6ucG+Os8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kOiUxZ1Fm3f",
        "colab_type": "text"
      },
      "source": [
        "## 2- Creating our model: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdCR3JawFm3k",
        "colab_type": "code",
        "outputId": "0f373235-3cfd-4f8f-9992-0771c7f729e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "source": [
        "#Import necessary keras specific libraries\n",
        "\n",
        "from keras.utils import np_utils\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras import backend as K\n",
        "\n",
        "# Setting Training Parameters like batch_size, epochs\n",
        "batch_size = 128\n",
        "epochs = 100\n",
        "\n",
        "# Storing the number of rows and columns\n",
        "img_rows = x_train[0].shape[0]\n",
        "img_cols = x_train[1].shape[0]\n",
        "\n",
        "''' Getting the data in the right 'shape' as required by Keras i.e. adding a 4th \n",
        "dimension to our data thereby changing the original image shape of (60000,28,28) \n",
        "to (60000,28,28,1)'''\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "# Storing the shape of a single image \n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "# Changing image type to float32 data type\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# Normalizing the data by changing the image pixel range from (0 to 255) to (0 to 1)\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Performing one hot encoding\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "# Calculate the number of classes and number of pixels \n",
        "num_classes = y_test.shape[1]\n",
        "num_pixels = x_train.shape[1] * x_train.shape[2]\n",
        "\n",
        "# Create CNN model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = keras.optimizers.Adadelta(),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,200,778\n",
            "Trainable params: 1,200,330\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzoS-5OcFm3w",
        "colab_type": "text"
      },
      "source": [
        "## 3- training our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bACuyHMEFm3y",
        "colab_type": "code",
        "outputId": "dd321522-608e-49ad-8c68-9a3e5cadba69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_fitting = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 271s 5ms/step - loss: 0.4585 - acc: 0.8422 - val_loss: 0.3300 - val_acc: 0.8787\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 272s 5ms/step - loss: 0.2916 - acc: 0.8960 - val_loss: 0.2524 - val_acc: 0.9081\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 274s 5ms/step - loss: 0.2407 - acc: 0.9132 - val_loss: 0.2350 - val_acc: 0.9131\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 274s 5ms/step - loss: 0.2125 - acc: 0.9236 - val_loss: 0.2263 - val_acc: 0.9182\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 274s 5ms/step - loss: 0.1881 - acc: 0.9333 - val_loss: 0.2190 - val_acc: 0.9212\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 274s 5ms/step - loss: 0.1711 - acc: 0.9387 - val_loss: 0.2234 - val_acc: 0.9196\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 275s 5ms/step - loss: 0.1571 - acc: 0.9433 - val_loss: 0.2259 - val_acc: 0.9199\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 279s 5ms/step - loss: 0.1448 - acc: 0.9481 - val_loss: 0.2430 - val_acc: 0.9227\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 279s 5ms/step - loss: 0.1313 - acc: 0.9530 - val_loss: 0.2418 - val_acc: 0.9192\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 274s 5ms/step - loss: 0.1217 - acc: 0.9548 - val_loss: 0.2533 - val_acc: 0.9244\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 274s 5ms/step - loss: 0.1130 - acc: 0.9594 - val_loss: 0.2486 - val_acc: 0.9247\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 275s 5ms/step - loss: 0.1099 - acc: 0.9596 - val_loss: 0.2231 - val_acc: 0.9296\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 275s 5ms/step - loss: 0.1016 - acc: 0.9623 - val_loss: 0.2345 - val_acc: 0.9263\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 277s 5ms/step - loss: 0.0948 - acc: 0.9652 - val_loss: 0.2506 - val_acc: 0.9317\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 275s 5ms/step - loss: 0.0875 - acc: 0.9683 - val_loss: 0.2538 - val_acc: 0.9275\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 274s 5ms/step - loss: 0.0880 - acc: 0.9678 - val_loss: 0.2398 - val_acc: 0.9295\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 273s 5ms/step - loss: 0.0805 - acc: 0.9711 - val_loss: 0.2678 - val_acc: 0.9297\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 274s 5ms/step - loss: 0.0769 - acc: 0.9721 - val_loss: 0.2503 - val_acc: 0.9285\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 275s 5ms/step - loss: 0.0738 - acc: 0.9734 - val_loss: 0.2281 - val_acc: 0.9301\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 272s 5ms/step - loss: 0.0679 - acc: 0.9754 - val_loss: 0.2759 - val_acc: 0.9335\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 272s 5ms/step - loss: 0.0672 - acc: 0.9759 - val_loss: 0.2819 - val_acc: 0.9315\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 276s 5ms/step - loss: 0.0689 - acc: 0.9753 - val_loss: 0.2404 - val_acc: 0.9303\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 275s 5ms/step - loss: 0.0648 - acc: 0.9767 - val_loss: 0.2727 - val_acc: 0.9297\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 275s 5ms/step - loss: 0.0623 - acc: 0.9772 - val_loss: 0.3015 - val_acc: 0.9295\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 277s 5ms/step - loss: 0.0601 - acc: 0.9784 - val_loss: 0.2453 - val_acc: 0.9289\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 278s 5ms/step - loss: 0.0594 - acc: 0.9784 - val_loss: 0.2621 - val_acc: 0.9287\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 277s 5ms/step - loss: 0.0532 - acc: 0.9807 - val_loss: 0.2477 - val_acc: 0.9321\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 278s 5ms/step - loss: 0.0569 - acc: 0.9800 - val_loss: 0.2330 - val_acc: 0.9312\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 277s 5ms/step - loss: 0.0503 - acc: 0.9818 - val_loss: 0.3018 - val_acc: 0.9326\n",
            "Epoch 30/100\n",
            "11904/60000 [====>.........................] - ETA: 3:31 - loss: 0.0544 - acc: 0.9804"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-16eea4421767>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           validation_data=(x_test, y_test))\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cehRVxQh7r4m",
        "colab_type": "text"
      },
      "source": [
        "## 4- Try yourself : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NQr-s4FUuJ7",
        "colab_type": "code",
        "outputId": "45e72bf7-ace2-41bd-8f64-ab14885ee0bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "\n",
        "# Import few more necessary libraries.\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "\n",
        "# Function to load and prepare the image in right shape\n",
        "def load_image(filename):\n",
        "\t# Load the image\n",
        "\timg = load_img(filename, grayscale=True, target_size=(28, 28))\n",
        "\t# Convert the image to array\n",
        "\timg = img_to_array(img)\n",
        "\t# Reshape the image into a sample of 1 channel\n",
        "\timg = img.reshape(1, 28, 28, 1)\n",
        "\t# Prepare it as pixel data\n",
        "\timg = img.astype('float32')\n",
        "\timg = img / 255.0\n",
        "\treturn img\n",
        "\n",
        "# Load an image and predict the apparel class\n",
        "img = load_image('/content/téléchargement (4).jfif')\n",
        "\n",
        "# Predict the apparel class\n",
        "class_prediction = model.predict_classes(img)\n",
        "print(class_prediction[0])\n",
        "\n",
        "#Map apparel category with the numerical class\n",
        "if class_prediction[0] == 0:\n",
        "  product = \"T-shirt/top\"\n",
        "elif class_prediction[0] == 1:\n",
        "  product = \"Trouser\"\n",
        "elif class_prediction[0] == 2:\n",
        "  product = \"Pullover\"\n",
        "elif class_prediction[0] == 3:\n",
        "  product = \"Dress\"\n",
        "elif class_prediction[0] == 4:\n",
        "  product = \"Coat\"\n",
        "elif class_prediction[0] == 5:\n",
        "  product = \"Sandal\"\n",
        "elif class_prediction[0] == 6:\n",
        "  product = \"Shirt\"\n",
        "elif class_prediction[0] == 7:\n",
        "  product = \"Sneaker\"\n",
        "elif class_prediction[0] == 8:\n",
        "  product = \"Bag\"\n",
        "else:\n",
        "  product = \"Ankle boot\"\n",
        "\n",
        "print(product)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n",
            "Bag\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py:104: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
            "  warnings.warn('grayscale is deprecated. Please use '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRpiauV68pbs",
        "colab_type": "text"
      },
      "source": [
        "## About :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JO9iZEkp8dRz",
        "colab_type": "text"
      },
      "source": [
        "*   This project was done by **Hazem BARKA** in order to finish the **IBM Artificial Intelligence Engineering Professional Certificate**.\n",
        "\n",
        "*   The work had been completed under the Data Science and Artificial Intelligence club of Tunisia Polytechnic School \"**Data C'EPT**\".\n",
        "\n",
        "\n",
        "\n",
        "![Texte alternatif…](https://drive.google.com/uc?id=1naUJn8xaksGr5c-rfsNv6gV0S9Y7aIGn)"
      ]
    }
  ]
}